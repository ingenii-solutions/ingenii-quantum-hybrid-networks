{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec892871-7bce-470d-8a10-c3416da9091c",
   "metadata": {},
   "source": [
    "# Hybrid Quantum Convolutional Neural Networks\n",
    "\n",
    "In this notebook we introduce the hybrid quantum-classical 2D CNN, which is designed to reduce the complexity of the classical 2D CNN, while maintaining its prediction performance. The hybrid CNN replaces a convolutional layer with a quantum convolutional layer. That is, each classical convolutional filter is replaced by a quantum circuit, which acts as a quantum filter. Each quantum circuit is divided into two blocks: the *data encoding*, which maps the input data into a quantum circuit, and the *quantum transformation*, where quantum operations are applied to retrieve information from the encoded data.\n",
    "\n",
    "\n",
    "## Data encoding: Flexible Representation of Quantum Images\n",
    "\n",
    "The first step is to encode the classical 3D image into a quantum circuit. The image is too big to fit on a quantum circuit, and we want to extract local features from the image to mimic what convolutional layers do. For this reason, we partition the images in (nxnxn) blocks, and fit each of these blocks in a quantum circuit. The encoding is called *Flexible Representation of Quantum Images*.\n",
    "\n",
    "This encoding consists of using the first qubit to encode the pixel value, and the others to encode the position of such pixel. \n",
    "\n",
    "$$\n",
    "\\renewcommand{\\ket}[1]{\\left|{#1}\\right\\rangle}\n",
    "\\renewcommand{\\bra}[1]{\\left\\langle{#1}\\right|}\n",
    "\\renewcommand{\\braket}[2]{\\left\\langle{#1}\\middle|{#2}\\right\\rangle}\n",
    "\\ket{I(\\theta)}=\\frac{1}{2^{n} }\\sum_{i=0}^{2^{2n}-1}\\left(\\cos \\theta_{i}\\ket{0}+\\sin\\theta_{i}\\ket{1}\\right)\\otimes\\ket{i}\n",
    "$$\n",
    "\n",
    "where the angles have been normalized between $[0, \\pi/2]$.  For example, take the 2x2 image\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\theta_{0},(00) & \\theta_{1},(01)  \\\\\n",
    "\\hline\n",
    "\\theta_{2},(10) & \\theta_{3},(11) \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The quantum state encoding this image is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ket{I}=\\frac{1}{2}[ \\; & \\phantom{+} \\left(\\cos\\theta_{0}\\ket{0}+\\sin\\theta_{0}\\ket{1} \\right)\\otimes\\ket{00}&\\\\\n",
    "& + \\left(\\cos\\theta_{1}\\ket{0}+\\sin\\theta_{1}\\ket{1} \\right)\\otimes\\ket{01} \\\\\n",
    "& + \\left(\\cos\\theta_{2}\\ket{0}+\\sin\\theta_{2}\\ket{1} \\right)\\otimes\\ket{10}\\\\\n",
    "& + \\left(\\cos\\theta_{3}\\ket{0}+\\sin\\theta_{3}\\ket{1} \\right)\\otimes\\ket{11} \\;]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Quantum transformation\n",
    "\n",
    "he use of quantum reservoirs (QR) is an emerging approach in quantum machine learning (QML), which has provided promising results in multiple tasks. It exploits the quantumness of a physical system to extract useful properties of the data that are then used to feed a machine learning model. In gate-based quantum computation, a QR is a *random* quantum circuit applied to an initial state, which encodes the input data, followed by measurements of local operators. These measurements are the features extracted by the model, which are then fed to a classical machine learning algorithm to predict the desired output. The main advantage of using QRs is the low complexity of the model, and thus, its easy training strategy. Instead of using parametrized quantum circuits and finding its optimal parameters, QRs use carefully selected quantum systems with no training parameters to transform the input data. These quantum filters consist of random quantum circuits, selected from a given family, with a fixed number of gates. The number of gates and the family of gates can be chosen by the user. We propose to use the following family of gates:\n",
    "\n",
    "$$\n",
    "G_3 = \\{H, CNOT, T\\}\n",
    "$$\n",
    "\n",
    "which has proven to provide optimal results in quantum machine learning (see https://journals.aps.org/pre/abstract/10.1103/PhysRevE.106.L043301). However, other families can be tested. Other implemented families are\n",
    "\n",
    "$$\n",
    "G1 = \\{CNOT, H, X\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "G2 = \\{CNOT, H, S\\}\n",
    "$$\n",
    "\n",
    "and the transverse-field Ising model, where the system is evolved under the evolution of the following Hamiltonian:\n",
    "\n",
    "$$\n",
    "H_{\\text{Ising}} = \\sum_{i,j=0}^{N-1} J_{ij} Z_iZ_j + \\sum_{i}^{N-1} h_{i} X_i,\n",
    "$$\n",
    "where $X_i$ and $Z_j$ are Pauli operators acting on the site $i, j$-th qubit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8367b2-4ede-4b2d-9f94-a1f2abfde7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "from torch import nn, tensor\n",
    "\n",
    "from ingenii_quantum.hybrid_networks.filters import QuantumFilters2D\n",
    "from ingenii_quantum.hybrid_networks.layers import QuantumLayer2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62379cf-78fd-4bd3-a125-6e6801afdd9d",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We load a 2D image, taken from the Qiskit tutorial:\n",
    "https://qiskit.org/textbook/ch-applications/quantum-edge-detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1dc76-6b35-43ee-9556-60df58044c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_size = 256       # Original image-width\n",
    "image_crop_size = 32   # Width of each part of image for processing\n",
    "\n",
    "\n",
    "# Load the image from filesystem\n",
    "image_raw = np.array(Image.open('images/edge-detection.png'))\n",
    "print('Raw Image info:', image_raw.shape)\n",
    "print('Raw Image datatype:', image_raw.dtype)\n",
    "\n",
    "# Convert the RBG component of the image to B&W image, as a numpy (uint8) array\n",
    "image = [\n",
    "    [\n",
    "        image_raw[i][j][0] / 255\n",
    "        for j in range(image_size)\n",
    "    ]\n",
    "    for i in range(image_size)\n",
    "]\n",
    "            \n",
    "image = np.array(image)\n",
    "print('Image shape (numpy array):', image.shape)\n",
    "\n",
    "\n",
    "# Display the image\n",
    "plt.title('Example Image')\n",
    "plt.xticks(range(0, image.shape[0]+1, 32))\n",
    "plt.yticks(range(0, image.shape[1]+1, 32))\n",
    "plt.imshow(image, extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50401f3a-6641-4f6e-9675-2b50ba4f8f13",
   "metadata": {},
   "source": [
    "## Example 2D Quantum filter\n",
    "\n",
    "Now we visualize an example of a 2D quantum filter, generated from the G3 family of gates. The quantum reservoirs contain 300 gates. Each data sample is separated in blocks of size n=4 and stride 1.  We run this example first in the Pytoch backend and then in some Qiskit backends (aer_simulator and fake backend), and compare the execution times.\n",
    "\n",
    "First we store the unitaries in a file, so that we can use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592bb66-cbb5-431e-8b72-cf8ffd3801cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_filters_2D = QuantumFilters2D(shape=(2,2), stride=1)\n",
    "\n",
    "quantum_filters_2D.generate_unitaries(\n",
    "    gates_name='G3', num_gates=50, num_filters=5,\n",
    "    num_features=1, save=True, unitaries_file_name='unitaries.pickle'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2ae7f-3fcb-4b50-a6d9-f5e267e97d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data\n",
    "data = tensor(image.reshape(1,1,256,256))\n",
    "\n",
    "start_time = time()\n",
    "result = quantum_filters_2D.get_quantum_filters(data, tol=1e-6)\n",
    "seconds_taken = time() - start_time\n",
    "minutes, seconds = round(seconds_taken // 60, 0), round(seconds_taken % 60, 0)\n",
    "print('Output shape = ', result.shape)\n",
    "print('Execution time with Pytorch backend: {str(minutes)} mins {str(seconds)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af1db75-a3a8-4ed3-8679-b4037dba4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.5,5))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "ax1.imshow(image, extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "ax2.imshow(result[0,3], extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de2920-66bf-42ca-a414-e959e216e69d",
   "metadata": {},
   "source": [
    "## Loading the unitaries\n",
    "\n",
    "Here we show an example loading the unitaries from the pickle file and running the script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47880a01-51f9-42e5-93b6-02ab800d0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_filters_2D = QuantumFilters2D(shape=(2,2), stride=1)\n",
    "\n",
    "quantum_filters_2D.load_unitaries(file_name='unitaries.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286eabb-b69c-4bd2-bdac-1efed2016e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "result = quantum_filters_2D.get_quantum_filters(data, tol=1e-6)\n",
    "seconds_taken = time() - start_time\n",
    "minutes, seconds = round(seconds_taken // 60, 0), round(seconds_taken % 60, 0)\n",
    "print('Output shape = ', result.shape)\n",
    "print(f'Execution time with Pytorch backend: {str(minutes)} mins {str(seconds)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8fc7a-5413-44a8-a746-f2a019dc526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.5,5))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "ax1.imshow(image, extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "ax2.imshow(result[0,3], extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59fa88-c51c-4184-8d8d-77375903ff27",
   "metadata": {},
   "source": [
    "## Running with Qiskit simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7afebf-3d2c-4818-9b7f-85ebfea1b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_filters_2D = QuantumFilters2D(shape=(2,2), stride=1, backend='aer_simulator', shots=100)\n",
    "\n",
    "quantum_filters_2D.generate_qc(gates_name='G3', num_gates=50, num_filters=5, num_features=1, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07966355-c2d3-49a2-a439-cff2c983e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this can take approx. 1 hour\n",
    "\n",
    "data = np.array(image).reshape(1,1,256,256)\n",
    "start_time = time()\n",
    "result = quantum_filters_2D.get_quantum_filters(data, tol=1e-4)\n",
    "seconds_taken = time() - start_time\n",
    "minutes, seconds = round(seconds_taken // 60, 0), round(seconds_taken % 60, 0)\n",
    "print('Output shape = ', result.shape)\n",
    "print(f'Execution time with Pytorch backend: {str(minutes)} mins {str(seconds)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e2eb9-739f-45e1-8bac-786bc163f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.5,5))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "ax1.imshow(image, extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "ax2.imshow(result[0,3], extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12183c6f-6dc7-4bce-bd7e-95a92a8a79e9",
   "metadata": {},
   "source": [
    "We see that running the code with quantum simulation using Qiskit is much slower than using Pytorch. Also, the results highly depend on the number of shots (the larger the better). With a very small number of shots we see that the outputs are significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f2616-4826-46f8-b0c7-3612c39a67e4",
   "metadata": {},
   "source": [
    "## Running with Qiskit fake provider\n",
    "\n",
    "Finally, we can run the code with a fake provider (or actual hardware if you have access to it) using Qiskit. We use bigger (nxn) blocks so that the execution is faster, and change the stride to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb81c49-75f8-4d5a-b5d6-7da8c5450ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.fake_provider import FakeMelbourne\n",
    "fake = FakeMelbourne()\n",
    "fake.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a087d-82f4-4602-995b-d37ab7fcdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_filters_2D = QuantumFilters2D(shape=(16,16), shots=100, backend =fake, stride=2)\n",
    "\n",
    "# Run this code to load the quantum circuits\n",
    "#quantum_filters_2D.load_gates(saved_gates_filename='gates_list_2D.pickle', saved_qubits_filename='qubits_list_2D.pickle')\n",
    "quantum_filters_2D.generate_qc(gates_name='G3', num_gates=50, num_filters=5, num_features=1, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91fcb4-80f7-4321-88ed-7d601290ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "data = tensor(image.reshape(1,1,256,256))\n",
    "\n",
    "# Note: this can take approx. 30 mins\n",
    "start_time = time()\n",
    "result = quantum_filters_2D.get_quantum_filters(data.numpy(), tol=1e-6)\n",
    "seconds_taken = time() - start_time\n",
    "minutes, seconds = round(seconds_taken // 60, 0), round(seconds_taken % 60, 0)\n",
    "print('Output shape = ', result.shape)\n",
    "print(f'Execution time for a single channel: {str(minutes)} mins {str(seconds)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcfe26-d22a-4219-b047-17eba0939ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.5,5))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "ax1.imshow(image, extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "ax2.imshow(result[0,3], extent=[0, image.shape[0], image.shape[1], 0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226619d-80ad-4217-be55-88982eee9692",
   "metadata": {},
   "source": [
    "We see that the execution time is even longer and the output is very noisy. The number of shots is very small, so we should try increasing it to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696a18d-5c86-4d04-97b0-aa9011e231ff",
   "metadata": {},
   "source": [
    "## Hybrid neural network: input layer\n",
    "\n",
    "Here we show an example of a hybrid quantum classical convolutional neural network, where the quantum filters are applied to the original data, and combined with the output of a classical convolutional layer. In this case, the quantum filters are used as a pre-processing step, and can be calculated to the whole dataset before the training of the model. \n",
    "\n",
    "<center>\n",
    "<img src=\"images/HybridCNN2D.png\" width=800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60623e70-75fb-42c7-870d-f3158a3bd73b",
   "metadata": {},
   "source": [
    "### 1. Calculate the quantum filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80981ea8-bbc3-4c84-8b08-373dc57c7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "data = tensor(image.reshape(1,1,256,256)).float()\n",
    "\n",
    "# Output of the quantum filters\n",
    "quantum_filters_2D = QuantumFilters2D(shape=(2,2), stride=1)\n",
    "quantum_filters_2D.generate_unitaries(gates_name='G3', num_gates=500, num_filters=64, num_features=1, save=False)\n",
    "data_QF = quantum_filters_2D.get_quantum_filters(data, tol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45c12a-6b5c-4298-b8c1-499027919c09",
   "metadata": {},
   "source": [
    "### 2. Define the classical CNN that uses both the original data and the quantum filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0111f5-4c4d-427d-b939-475d7573b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_hybrid1(nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim=1, num_filters=[64,128,256], verbose=False):\n",
    "        super(Model_hybrid1, self).__init__()\n",
    "        \n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_filters = num_filters\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.conv1 = nn.Conv2d(feat_dim, num_filters[0], 7, 1, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters[0])\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(num_filters[0], self.num_filters[1], 7, 4, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_filters[1])\n",
    "        self.max_pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(self.num_filters[1], self.num_filters[2], 5, 2, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_filters[2])\n",
    "        self.max_pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc1 = nn.Linear(65536, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x, x_quantum):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "        if x_quantum.dim() == 1:\n",
    "            x_quantum = x_quantum.unsqueeze(-1)\n",
    "        if self.verbose:\n",
    "            print('Input', list(x.size()), ' Input quantum', list(x_quantum.size()))\n",
    "        \n",
    "        conv1= self.conv1(x)\n",
    "        if self.verbose:\n",
    "            print('Conv1 (7x7x7)', list(conv1.shape))\n",
    "\n",
    "        conv1_res1 = x_quantum + conv1\n",
    "        if self.verbose:\n",
    "            print('Conv1 + Quantum', list(conv1_res1.shape))\n",
    "\n",
    "        conv2 = self.conv2(conv1_res1)\n",
    "        conv2 = self.bn2(self.relu(conv2))\n",
    "        if self.verbose:\n",
    "            print('Conv2 (7x7x7)', list(conv2.shape))\n",
    "        \n",
    "        pool1 = self.max_pool1(conv2)\n",
    "        if self.verbose:\n",
    "            print('Pooling 1', list(pool1.shape))\n",
    "            \n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv3 = self.bn3(self.relu(conv3))\n",
    "        if self.verbose:\n",
    "            print('Conv 3 (7x7x7)',list(conv3.shape))\n",
    "\n",
    "        pool2 = self.max_pool2(conv3)\n",
    "        if self.verbose:\n",
    "            print('Pooling 2', list(pool2.shape))\n",
    "\n",
    "        flatten = pool2.view(pool2.size(0), -1)\n",
    "        if self.verbose:\n",
    "            print('Flatten', list(flatten.shape))\n",
    "\n",
    "        fc1 = self.fc1(flatten)\n",
    "        fc1 = self.relu(fc1)\n",
    "        if self.verbose:\n",
    "            print('Fc1', list(fc1.shape))\n",
    "\n",
    "        fc2 = self.fc2(fc1)\n",
    "        if self.verbose:\n",
    "            print('Fc2', list(fc2.shape))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb52ba-2c5e-45b2-ac9d-276f940427f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_hybrid1(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3113b3-cd87-4bb8-8900-1fcda44b3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_batch= model(data, data_QF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4b222-9d01-42dc-9828-533b2e76f994",
   "metadata": {},
   "source": [
    "## Hybrid neural network: convolutional layer\n",
    "\n",
    "Instead of using the quantum layer as a pre-processing step, we can use the quantum filter as a layer of the network. For this, we need to use the *QuantumLayer3D* function.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/HybridCNN2Db.png\" width=800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e73e7-0c15-4faa-81b8-9d5ca9d3e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data (no need to apply the quantum filters now)\n",
    "data = tensor(image.reshape(1,1,256,256)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404f060-88ad-4fd5-bba1-ec929e997c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_hybrid2(nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim=1, num_filters=[64,64,128], use_cuda=True, verbose=False,\n",
    "                 shape=(4,4), gates_name='G3', num_gates=300,  tol=1e-6,stride=4,\n",
    "                 load_unitaries_file_name=False, unitaries_file_name='unitaries.pickle'):\n",
    "        super(Model_hybrid2, self).__init__()\n",
    "        \n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_filters = num_filters\n",
    "        self.use_cuda = use_cuda\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.quantumlayer = QuantumLayer2D(\n",
    "            shape,feat_dim, gates_name, num_gates, num_filters[0], tol, stride,\n",
    "            load_unitaries_file_name=load_unitaries_file_name, unitaries_file_name=unitaries_file_name\n",
    "        )\n",
    "            \n",
    "        self.conv1 = nn.Conv2d(feat_dim, num_filters[0], 7, 1, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters[0])\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(num_filters[0], self.num_filters[1], 7, 4, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_filters[1])\n",
    "        self.max_pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(self.num_filters[1], self.num_filters[2], 5, 2, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_filters[2])\n",
    "        self.max_pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "        if self.verbose:\n",
    "            print('Input', list(x.size()))\n",
    "        \n",
    "        conv1= self.conv1(x)\n",
    "        conv1 = self.bn1(self.relu(conv1))\n",
    "        if self.verbose:\n",
    "            print('Conv1 (7x7x7)', list(conv1.shape))\n",
    "\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv2 = self.bn2(self.relu(conv2))\n",
    "        if self.verbose:\n",
    "            print('Conv2 (7x7x7)', list(conv2.shape))\n",
    "        \n",
    "        quantum_conv = self.quantumlayer(conv1)       \n",
    "        if self.verbose:\n",
    "            print('Quantum filter ', list(quantum_conv.shape))\n",
    "            \n",
    "        conv2_quantum = conv2 + quantum_conv\n",
    "        if self.verbose:\n",
    "            print('Conv2 + Quantum filter ', list(conv2_quantum.shape))\n",
    "            \n",
    "        pool1 = self.max_pool1(conv2_quantum)\n",
    "        if self.verbose:\n",
    "            print('Pooling 1', list(pool1.shape))\n",
    "            \n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv3 = self.bn3(self.relu(conv3))\n",
    "        if self.verbose:\n",
    "            print('Conv 3 (7x7x7)',list(conv3.shape))\n",
    "\n",
    "        pool2 = self.max_pool2(conv3)\n",
    "        if self.verbose:\n",
    "            print('Pooling 2', list(pool2.shape))\n",
    "\n",
    "        flatten = pool2.view(pool2.size(0), -1)\n",
    "        if self.verbose:\n",
    "            print('Flatten', list(flatten.shape))\n",
    "\n",
    "        fc1 = self.fc1(flatten)\n",
    "        fc1 = self.relu(fc1)\n",
    "        if self.verbose:\n",
    "            print('Fc1', list(fc1.shape))\n",
    "\n",
    "        fc2 = self.fc2(fc1)\n",
    "        if self.verbose:\n",
    "            print('Fc2', list(fc2.shape))\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490487c-eb47-4545-b8eb-d345a1a69e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_hybrid2(use_cuda=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670d27c-1d4c-437a-81d1-5b607aa59982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_batch = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff595f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
